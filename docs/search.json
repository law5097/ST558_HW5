[
  {
    "objectID": "ST558_HW5.html",
    "href": "ST558_HW5.html",
    "title": "ST558 HW5 - Lee Worthington",
    "section": "",
    "text": "Using CV with a random forest model allows you to:\n\nTune the hyperparameters of the random forest model to find the “optimal” hyperparameters and prevent overfitting\nEstimate the performance of the model on unseen test data using the 1 of k folds as the test set\n\n\n\n\n\n\nA bagged tree model involves:\n\nGenerating multiple datasets by sampling with replacement from the original dataset samples of size n\nFitting a decision tree on each bootstrapped sample\nGenerating a prediction with each tree\nThen generally taking the average or mode of the tree predictions in order to generate the final prediction\n\n\n\n\n\n\nA generAL linear model is a linear model where the response is continuous and normal, that allows for both continuous and categorical predictors.\n\n\n\n\n\nIn MLR including an interaction term allows you to capture the combined effect of multiple predictors on the target variable.\n\n\nBasically it allows the model to capture situations where a predictors effect on the target depends on another predictor. For instance if you had a sex*height interaction term for predicting weight the effect of height on weight may vary based on sex.\n\n\n\n\n\nThe main purpose of a test set is to obtain an unbiased assessment of how a model generalizes to unseen data. To accomplish this, we need to split our full dataset into a training set, which is used to fit and tune the model, and a completely separate test set containing unseen data, on which we can measure the accuracy and performance of the trained model.\n\n\nThis ensures that the evaluation metrics reflect the model’s ability to perform on new, unseen data, rather than just the data it was trained on."
  },
  {
    "objectID": "ST558_HW5.html#task-2-fitting-models",
    "href": "ST558_HW5.html#task-2-fitting-models",
    "title": "ST558 HW5 - Lee Worthington",
    "section": "Task 2: fitting models",
    "text": "Task 2: fitting models\n\nQuestion 1 - Understand the data\n\nLoad and summarize the data\n\n# load libraries\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(caret)\n\n# Read in the data\nheart_data_1 <- read_csv(\n  'C:\\\\Users\\\\lawor\\\\OneDrive\\\\Desktop\\\\School\\\\ST 558\\\\Homework\\\\ST558_HW5\\\\heart.csv',\n  show_col_types = FALSE\n)\n\n# Print summary\nsummary(heart_data_1)\n\n      Age            Sex            ChestPainType        RestingBP    \n Min.   :28.00   Length:918         Length:918         Min.   :  0.0  \n 1st Qu.:47.00   Class :character   Class :character   1st Qu.:120.0  \n Median :54.00   Mode  :character   Mode  :character   Median :130.0  \n Mean   :53.51                                         Mean   :132.4  \n 3rd Qu.:60.00                                         3rd Qu.:140.0  \n Max.   :77.00                                         Max.   :200.0  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   :  0.0   Min.   :0.0000   Length:918         Min.   : 60.0  \n 1st Qu.:173.2   1st Qu.:0.0000   Class :character   1st Qu.:120.0  \n Median :223.0   Median :0.0000   Mode  :character   Median :138.0  \n Mean   :198.8   Mean   :0.2331                      Mean   :136.8  \n 3rd Qu.:267.0   3rd Qu.:0.0000                      3rd Qu.:156.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:918         Min.   :-2.6000   Length:918         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.6000   Mode  :character   Median :1.0000  \n                    Mean   : 0.8874                      Mean   :0.5534  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n# Print level count to confirm on these categorical/binary fields\nheart_data_1 |> \n  summarise(\n    Sex = length(unique(Sex)),\n    ChestPainType = length(unique(ChestPainType)),\n    FastingBS = length(unique(FastingBS)),\n    RestingECG = length(unique(RestingECG)),\n    ExerciseAngina = length(unique(ExerciseAngina)),\n    ST_Slope = length(unique(ST_Slope)),\n    HeartDisease = length(unique(HeartDisease))\n  ) |>\n  print()\n\n# A tibble: 1 × 7\n    Sex ChestPainType FastingBS RestingECG ExerciseAngina ST_Slope HeartDisease\n  <int>         <int>     <int>      <int>          <int>    <int>        <int>\n1     2             4         2          3              2        3            2\n\n\n\nBase on the summary data (and eyeballing the csv):\n\nAge, RestingBP, Cholsterol, MaxHR, and Oldpeak are continuous\nChestPainType, RestingECG, and ST_Slope are characters\nSex, FastingBS, ExerciseAngina, and HeartDisease are binary\n\n\n\n\nCount missing values with respect ot HeartDisease\n\n# Count missing values grouped by HeartDisease and print @@@@@@@@@@@@@@@@@@@@@\nheart_data_1 |>\n  group_by(HeartDisease) |>\n  summarise_all(~sum(is.na(.))) |>\n  gather(key = \"Variable\", value = \"MissingValues\", -HeartDisease) |>\n  arrange(desc(MissingValues), HeartDisease) |>\n  print()\n\n# A tibble: 22 × 3\n   HeartDisease Variable       MissingValues\n          <dbl> <chr>                  <int>\n 1            0 Age                        0\n 2            0 Sex                        0\n 3            0 ChestPainType              0\n 4            0 RestingBP                  0\n 5            0 Cholesterol                0\n 6            0 FastingBS                  0\n 7            0 RestingECG                 0\n 8            0 MaxHR                      0\n 9            0 ExerciseAngina             0\n10            0 Oldpeak                    0\n# ℹ 12 more rows\n\n\n\nThere appear to be no missing values at all, looking at the raw data confirms this as well\n\n\n\nPlots focusing on HeartDisease\n\n# Generate pair plots in chunks so this is readable\nGGally::ggpairs(heart_data_1, columns = c(12, 1, 2))\n\n\n\nGGally::ggpairs(heart_data_1, columns = c(12, 3, 4))\n\n\n\nGGally::ggpairs(heart_data_1, columns = c(12, 5, 6))\n\n\n\nGGally::ggpairs(heart_data_1, columns = c(12, 7, 8))\n\n\n\nGGally::ggpairs(heart_data_1, columns = c(12, 9, 10))\n\n\n\nGGally::ggpairs(heart_data_1, columns = c(12, 11))\n\n\n\n\n\nBased on these plots, in terms of impact on HeartDisease these variarbles seem to have a large effect:\n\nChestPainType\nExerciseAngina\nST_Slope\n\n\n\n\n\nQuestion 2 - Create new variables\n\n# Convert columns to appropriate data types\nheart_data_2 <- heart_data_1 |>\n  mutate(HeartDiseaseFactor = as.factor(HeartDisease)) |>\n  select(-ST_Slope, -HeartDisease)\n\n# Print output\nhead(heart_data_2, 5)\n\n# A tibble: 5 × 11\n    Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n  <dbl> <chr> <chr>             <dbl>       <dbl>     <dbl> <chr>      <dbl>\n1    40 M     ATA                 140         289         0 Normal       172\n2    49 F     NAP                 160         180         0 Normal       156\n3    37 M     ATA                 130         283         0 ST            98\n4    48 F     ASY                 138         214         0 Normal       108\n5    54 M     NAP                 150         195         0 Normal       122\n# ℹ 3 more variables: ExerciseAngina <chr>, Oldpeak <dbl>,\n#   HeartDiseaseFactor <fct>\n\n\n\n\nQuestion 3 - Create dummy variables\n\n# Create dummy variables for categorical predictors\ndummies <- dummyVars(~ Sex + ExerciseAngina + ChestPainType + RestingECG, data = heart_data_2)\ndummy_data <- predict(dummies, newdata = heart_data_2)\n\n# Convert dummy_data to a data frame\ndummy_data <- as.data.frame(dummy_data)\n\n# Combine the dummy variables with the original dataset\nheart_data_3 <- bind_cols(heart_data_2, dummy_data)\n\n# Print the updated heart_data\nprint(heart_data_3)\n\n# A tibble: 918 × 22\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n * <dbl> <chr> <chr>             <dbl>       <dbl>     <dbl> <chr>      <dbl>\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 14 more variables: ExerciseAngina <chr>, Oldpeak <dbl>,\n#   HeartDiseaseFactor <fct>, SexF <dbl>, SexM <dbl>, ExerciseAnginaN <dbl>,\n#   ExerciseAnginaY <dbl>, ChestPainTypeASY <dbl>, ChestPainTypeATA <dbl>,\n#   ChestPainTypeNAP <dbl>, ChestPainTypeTA <dbl>, RestingECGLVH <dbl>,\n#   RestingECGNormal <dbl>, RestingECGST <dbl>\n\n\n\n\nSplit the data\n\n# Set seed then do a stratified split\nset.seed(1)  \ntrain_index <- createDataPartition(heart_data_3$HeartDiseaseFactor, p = 0.8, list = FALSE)\ntrain_data <- heart_data_3[train_index, ]\ntest_data <- heart_data_3[-train_index, ]\n\n# check results\nnrow(train_data)\n\n[1] 735\n\nnrow(test_data)\n\n[1] 183\n\n\n\n\nFit KNN model with Caret\n\n# Fit KNN model, here im trying to define all the options in line instead of as seperate objects to call\nknn_model <- train(\n  HeartDiseaseFactor ~ .,\n  data = train_data |> select(-Age, -Sex, -ChestPainType, -RestingECG, -ExerciseAngina),\n  method = \"knn\",\n  trControl = trainControl(method = \"repeatedcv\", number = 10, repeats = 3),\n  tuneGrid = expand.grid(k = 1:40),\n  preProcess = c(\"center\", \"scale\")\n)\n\n# Fit summary\nsummary(knn_model)\n\n            Length Class      Mode     \nlearn        2     -none-     list     \nk            1     -none-     numeric  \ntheDots      0     -none-     list     \nxNames      16     -none-     character\nproblemType  1     -none-     character\ntuneValue    1     data.frame list     \nobsLevels    2     -none-     character\nparam        0     -none-     list     \n\n# Generate predictions\ntest_data$HeartDiseaseKNN <- predict(knn_model, newdata = test_data)\n\n# Print confusion matrix\nconfusionMatrix(test_data$HeartDiseaseFactor, test_data$HeartDiseaseKNN)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 64 18\n         1 14 87\n                                          \n               Accuracy : 0.8251          \n                 95% CI : (0.7622, 0.8772)\n    No Information Rate : 0.5738          \n    P-Value [Acc > NIR] : 3.868e-13       \n                                          \n                  Kappa : 0.6448          \n                                          \n Mcnemar's Test P-Value : 0.5959          \n                                          \n            Sensitivity : 0.8205          \n            Specificity : 0.8286          \n         Pos Pred Value : 0.7805          \n         Neg Pred Value : 0.8614          \n             Prevalence : 0.4262          \n         Detection Rate : 0.3497          \n   Detection Prevalence : 0.4481          \n      Balanced Accuracy : 0.8245          \n                                          \n       'Positive' Class : 0"
  }
]